#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
å¿«é€Ÿæµ‹è¯•è„šæœ¬ - é…å¥—train_v2.py
ç®€å•å¿«é€Ÿåœ°æµ‹è¯•æ¨¡å‹åŸºæœ¬åŠŸèƒ½
"""

import torch
import cv2
import numpy as np
from pathlib import Path
import logging
from train import FixedCRNN, MathCaptchaDataset

logging.basicConfig(level=logging.INFO, format='%(message)s')
logger = logging.getLogger(__name__)

def quick_test():
    """å¿«é€Ÿæµ‹è¯•æ¨¡å‹"""
    print("ğŸš€ å¿«é€Ÿæµ‹è¯• v2")
    print("=" * 40)
    
    # 1. æ£€æŸ¥æ¨¡å‹æ–‡ä»¶
    model_path = Path('checkpoints/best_model_v2.pth')
    if not model_path.exists():
        print("âŒ æ‰¾ä¸åˆ°æ¨¡å‹æ–‡ä»¶: checkpoints/best_model_v2.pth")
        print("ğŸ’¡ è¯·å…ˆè¿è¡Œ: python train.py")
        return
    
    # 2. åŠ è½½æ¨¡å‹
    try:
        checkpoint = torch.load(model_path, map_location='cpu', weights_only=False)
        char_to_idx = checkpoint['char_to_idx']
        idx_to_char = checkpoint['idx_to_char']
        
        model = FixedCRNN(num_classes=len(char_to_idx))
        model.load_state_dict(checkpoint['model_state_dict'])
        model.eval()
        
        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        model = model.to(device)
        
        print(f"âœ… æ¨¡å‹åŠ è½½æˆåŠŸ")
        print(f"ğŸ“Š å­—ç¬¦é›†å¤§å°: {len(char_to_idx)}")
        print(f"ğŸ”§ è®¾å¤‡: {device}")
        
    except Exception as e:
        print(f"âŒ æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
        return
    
    # 3. æ£€æŸ¥æµ‹è¯•æ•°æ®
    test_dir = Path('data/generated/test')
    if not test_dir.exists():
        print("âŒ æ‰¾ä¸åˆ°æµ‹è¯•æ•°æ®ç›®å½•")
        return
    
    try:
        dataset = MathCaptchaDataset(test_dir, char_to_idx, 'test')
        print(f"âœ… æµ‹è¯•æ•°æ®åŠ è½½æˆåŠŸ: {len(dataset)} ä¸ªæ ·æœ¬")
    except Exception as e:
        print(f"âŒ æµ‹è¯•æ•°æ®åŠ è½½å¤±è´¥: {e}")
        return
    
    # 4. å¿«é€Ÿé¢„æµ‹å‡ ä¸ªæ ·æœ¬
    print(f"\nğŸ§ª æµ‹è¯• 5 ä¸ªéšæœºæ ·æœ¬:")
    print("-" * 40)
    
    import random
    test_indices = random.sample(range(len(dataset)), min(5, len(dataset)))
    
    correct = 0
    for i, idx in enumerate(test_indices, 1):
        img, _, true_text, answer = dataset[idx]
        
        # é¢„æµ‹
        img = img.unsqueeze(0).to(device)
        with torch.no_grad():
            log_probs = model(img)
            predictions = model.decode(log_probs, idx_to_char)
        
        predicted = predictions[0] if predictions else ""
        is_correct = predicted == true_text
        if is_correct:
            correct += 1
        
        # è¾“å‡ºç»“æœ
        status = "âœ…" if is_correct else "âŒ"
        type_icon = "ğŸ‡¨ğŸ‡³" if any('\u4e00' <= c <= '\u9fff' for c in true_text) else "ğŸ”¢"
        print(f"{i}. {type_icon} {status} {true_text} â†’ {predicted}")
    
    # 5. æ€»ç»“
    accuracy = correct / len(test_indices) * 100
    print(f"\nğŸ“ˆ å¿«é€Ÿæµ‹è¯•å‡†ç¡®ç‡: {accuracy:.1f}% ({correct}/{len(test_indices)})")
    
    if accuracy >= 80:
        print("ğŸ‰ æ¨¡å‹è¡¨ç°ä¼˜ç§€ï¼")
    elif accuracy >= 50:
        print("âœ… æ¨¡å‹è¡¨ç°è‰¯å¥½")
    elif accuracy >= 20:
        print("âš ï¸ æ¨¡å‹è¡¨ç°ä¸€èˆ¬")
    else:
        print("ğŸ”´ æ¨¡å‹éœ€è¦é‡æ–°è®­ç»ƒ")
    
    print(f"\nğŸ’¡ è¿è¡Œå®Œæ•´æµ‹è¯•: python test_v2.py")

if __name__ == "__main__":
    quick_test() 