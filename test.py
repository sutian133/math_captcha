#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
é…å¥—train_v2.pyçš„æµ‹è¯•è„šæœ¬
æµ‹è¯•ä¿®å¤åçš„æ•°å­¦éªŒè¯ç è¯†åˆ«æ¨¡å‹
"""

import torch
import cv2
import numpy as np
import json
from pathlib import Path
import logging
import random
from train import FixedCRNN, MathCaptchaDataset, analyze_dataset_chars, create_char_mapping

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

def load_model_v2(checkpoint_path='checkpoints/best_model_v2.pth'):
    """åŠ è½½è®­ç»ƒå¥½çš„v2æ¨¡å‹"""
    if not Path(checkpoint_path).exists():
        logger.error(f"âŒ æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨: {checkpoint_path}")
        logger.info("ğŸ’¡ è¯·å…ˆè¿è¡Œè®­ç»ƒè„šæœ¬: python train.py")
        return None, None, None, False

    try:
        checkpoint = torch.load(checkpoint_path, map_location='cpu', weights_only=False)
        
        char_to_idx = checkpoint['char_to_idx']
        idx_to_char = checkpoint['idx_to_char']
        
        model = FixedCRNN(num_classes=len(char_to_idx))
        model.load_state_dict(checkpoint['model_state_dict'])
        model.eval()
        
        logger.info(f"âœ… æ¨¡å‹åŠ è½½æˆåŠŸ: {checkpoint_path}")
        logger.info(f"ğŸ“Š å­—ç¬¦é›†å¤§å°: {len(char_to_idx)}")
        logger.info(f"ğŸ¯ è®­ç»ƒè½®æ¬¡: {checkpoint.get('epoch', 'N/A')}")
        logger.info(f"ğŸ“ˆ æœ€ä½³æŸå¤±: {checkpoint.get('loss', 'N/A'):.4f}")
        
        return model, char_to_idx, idx_to_char, True
        
    except Exception as e:
        logger.error(f"âŒ æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
        return None, None, None, False

def preprocess_single_image(image_path, target_size=(160, 60)):
    """é¢„å¤„ç†å•å¼ å›¾ç‰‡"""
    img = cv2.imread(str(image_path))
    if img is None:
        logger.error(f"æ— æ³•è¯»å–å›¾ç‰‡: {image_path}")
        return None
    
    # è°ƒæ•´å¤§å°
    img = cv2.resize(img, target_size)
    
    # å½’ä¸€åŒ–
    img = img.astype(np.float32) / 255.0
    
    # è½¬æ¢ä¸ºtensor (H, W, C) -> (C, H, W)
    img_tensor = torch.from_numpy(img).permute(2, 0, 1)
    
    # æ·»åŠ batchç»´åº¦
    img_tensor = img_tensor.unsqueeze(0)  # (1, C, H, W)
    
    return img_tensor

def predict_single_image(model, image_path, idx_to_char, device):
    """é¢„æµ‹å•å¼ å›¾ç‰‡"""
    img_tensor = preprocess_single_image(image_path)
    if img_tensor is None:
        return ""
    
    img_tensor = img_tensor.to(device)
    
    with torch.no_grad():
        log_probs = model(img_tensor)  # (seq_len, batch_size, num_classes)
        predictions = model.decode(log_probs, idx_to_char)
    
    return predictions[0] if predictions else ""

def test_dataset_v2(model, char_to_idx, idx_to_char, device, data_dir='data/generated/test', num_samples=20):
    """æµ‹è¯•æ•°æ®é›†"""
    if not Path(data_dir).exists():
        logger.error(f"âŒ æµ‹è¯•æ•°æ®ç›®å½•ä¸å­˜åœ¨: {data_dir}")
        return 0.0
    
    dataset = MathCaptchaDataset(data_dir, char_to_idx, 'test')
    
    # éšæœºé€‰æ‹©æ ·æœ¬æµ‹è¯•
    total_samples = len(dataset)
    test_indices = random.sample(range(total_samples), min(num_samples, total_samples))
    
    correct = 0
    total = len(test_indices)
    
    logger.info(f"ğŸ§ª æµ‹è¯• {total} ä¸ªæ ·æœ¬...")
    logger.info("-" * 60)
    
    for i, idx in enumerate(test_indices, 1):
        img, char_indices, true_text, answer = dataset[idx]
        
        # é¢„å¤„ç†å›¾ç‰‡
        img = img.unsqueeze(0).to(device)  # æ·»åŠ batchç»´åº¦
        
        # é¢„æµ‹
        with torch.no_grad():
            log_probs = model(img)
            predictions = model.decode(log_probs, idx_to_char)
        
        predicted_text = predictions[0] if predictions else ""
        is_correct = predicted_text == true_text
        
        if is_correct:
            correct += 1
        
        # æ˜¾ç¤ºç»“æœ
        type_icon = "ğŸ‡¨ğŸ‡³" if any('\u4e00' <= char <= '\u9fff' for char in true_text) else "ğŸ”¢"
        status = "âœ…" if is_correct else "âŒ"
        
        logger.info(f"{i:2d}. {type_icon} {status}")
        logger.info(f"    çœŸå®: {true_text}")
        logger.info(f"    é¢„æµ‹: {predicted_text}")
        logger.info(f"    ç­”æ¡ˆ: {answer}")
        
        # å¦‚æœé¢„æµ‹é”™è¯¯ï¼Œæ˜¾ç¤ºè¯¦ç»†ä¿¡æ¯
        if not is_correct:
            logger.info(f"    ğŸ” å­—ç¬¦å·®å¼‚åˆ†æ:")
            logger.info(f"       çœŸå®é•¿åº¦: {len(true_text)}, é¢„æµ‹é•¿åº¦: {len(predicted_text)}")
            for j, (t, p) in enumerate(zip(true_text, predicted_text)):
                if t != p:
                    logger.info(f"       ä½ç½®{j}: '{t}' vs '{p}'")
        logger.info("")
    
    accuracy = correct / total * 100
    
    logger.info("ğŸ“Š æµ‹è¯•ç»“æœæ±‡æ€»:")
    logger.info("-" * 60)
    logger.info(f"âœ… æ­£ç¡®é¢„æµ‹: {correct}")
    logger.info(f"âŒ é”™è¯¯é¢„æµ‹: {total - correct}")
    logger.info(f"ğŸ“ˆ å‡†ç¡®ç‡: {accuracy:.2f}% ({correct}/{total})")
    
    return accuracy

def analyze_model_performance(model, char_to_idx, idx_to_char, device, data_dir='data/generated/test'):
    """åˆ†ææ¨¡å‹æ€§èƒ½"""
    logger.info("\nğŸ” æ¨¡å‹æ€§èƒ½è¯¦ç»†åˆ†æ:")
    logger.info("=" * 60)
    
    if not Path(data_dir).exists():
        logger.error(f"âŒ æµ‹è¯•æ•°æ®ç›®å½•ä¸å­˜åœ¨: {data_dir}")
        return
    
    dataset = MathCaptchaDataset(data_dir, char_to_idx, 'test')
    
    # æŒ‰ç±»å‹åˆ†ç±»ç»Ÿè®¡
    chinese_correct = 0
    chinese_total = 0
    english_correct = 0
    english_total = 0
    
    # æµ‹è¯•æ‰€æœ‰æ ·æœ¬
    for i in range(min(100, len(dataset))):  # æœ€å¤šæµ‹è¯•100ä¸ªæ ·æœ¬
        img, char_indices, true_text, answer = dataset[i]
        
        # é¢„æµ‹
        img = img.unsqueeze(0).to(device)
        with torch.no_grad():
            log_probs = model(img)
            predictions = model.decode(log_probs, idx_to_char)
        
        predicted_text = predictions[0] if predictions else ""
        is_correct = predicted_text == true_text
        
        # åˆ†ç±»ç»Ÿè®¡
        if any('\u4e00' <= char <= '\u9fff' for char in true_text):
            chinese_total += 1
            if is_correct:
                chinese_correct += 1
        else:
            english_total += 1
            if is_correct:
                english_correct += 1
    
    # è¾“å‡ºåˆ†æç»“æœ
    chinese_acc = chinese_correct / chinese_total * 100 if chinese_total > 0 else 0
    english_acc = english_correct / english_total * 100 if english_total > 0 else 0
    total_acc = (chinese_correct + english_correct) / (chinese_total + english_total) * 100
    
    logger.info(f"ğŸ‡¨ğŸ‡³ ä¸­æ–‡éªŒè¯ç :")
    logger.info(f"   æ ·æœ¬æ•°: {chinese_total}")
    logger.info(f"   æ­£ç¡®æ•°: {chinese_correct}")
    logger.info(f"   å‡†ç¡®ç‡: {chinese_acc:.2f}%")
    
    logger.info(f"\nğŸ”¢ è‹±æ–‡éªŒè¯ç :")
    logger.info(f"   æ ·æœ¬æ•°: {english_total}")
    logger.info(f"   æ­£ç¡®æ•°: {english_correct}")
    logger.info(f"   å‡†ç¡®ç‡: {english_acc:.2f}%")
    
    logger.info(f"\nğŸ“Š æ•´ä½“æ€§èƒ½:")
    logger.info(f"   æ€»æ ·æœ¬: {chinese_total + english_total}")
    logger.info(f"   æ€»æ­£ç¡®: {chinese_correct + english_correct}")
    logger.info(f"   æ€»å‡†ç¡®ç‡: {total_acc:.2f}%")

def show_prediction_samples(model, char_to_idx, idx_to_char, device, data_dir='data/generated/test'):
    """æ˜¾ç¤ºé¢„æµ‹æ ·æœ¬ï¼ˆç”¨äºè°ƒè¯•ï¼‰"""
    logger.info("\nğŸ–¼ï¸ é¢„æµ‹æ ·æœ¬å±•ç¤º:")
    logger.info("-" * 40)
    
    if not Path(data_dir).exists():
        logger.error(f"âŒ æµ‹è¯•æ•°æ®ç›®å½•ä¸å­˜åœ¨: {data_dir}")
        return
    
    dataset = MathCaptchaDataset(data_dir, char_to_idx, 'test')
    
    # é€‰æ‹©ä¸åŒç±»å‹çš„æ ·æœ¬
    chinese_samples = []
    english_samples = []
    
    for i in range(min(50, len(dataset))):
        _, _, true_text, _ = dataset[i]
        if any('\u4e00' <= char <= '\u9fff' for char in true_text):
            if len(chinese_samples) < 3:
                chinese_samples.append(i)
        else:
            if len(english_samples) < 3:
                english_samples.append(i)
        
        if len(chinese_samples) >= 3 and len(english_samples) >= 3:
            break
    
    # æ˜¾ç¤ºä¸­æ–‡æ ·æœ¬
    if chinese_samples:
        logger.info("\nğŸ‡¨ğŸ‡³ ä¸­æ–‡æ ·æœ¬:")
        for i, idx in enumerate(chinese_samples, 1):
            img, _, true_text, answer = dataset[idx]
            img = img.unsqueeze(0).to(device)
            
            with torch.no_grad():
                log_probs = model(img)
                predictions = model.decode(log_probs, idx_to_char)
            
            predicted = predictions[0] if predictions else ""
            status = "âœ…" if predicted == true_text else "âŒ"
            logger.info(f"  {i}. {true_text} â†’ {predicted} {status}")
    
    # æ˜¾ç¤ºè‹±æ–‡æ ·æœ¬
    if english_samples:
        logger.info("\nğŸ”¢ è‹±æ–‡æ ·æœ¬:")
        for i, idx in enumerate(english_samples, 1):
            img, _, true_text, answer = dataset[idx]
            img = img.unsqueeze(0).to(device)
            
            with torch.no_grad():
                log_probs = model(img)
                predictions = model.decode(log_probs, idx_to_char)
            
            predicted = predictions[0] if predictions else ""
            status = "âœ…" if predicted == true_text else "âŒ"
            logger.info(f"  {i}. {true_text} â†’ {predicted} {status}")

def test_single_image_file(image_path):
    """æµ‹è¯•å•ä¸ªå›¾ç‰‡æ–‡ä»¶"""
    logger.info(f"\nğŸ–¼ï¸ æµ‹è¯•å•å¼ å›¾ç‰‡: {image_path}")
    logger.info("-" * 40)
    
    # åŠ è½½æ¨¡å‹
    model, char_to_idx, idx_to_char, success = load_model_v2()
    if not success:
        return
    
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    model = model.to(device)
    
    # é¢„æµ‹
    prediction = predict_single_image(model, image_path, idx_to_char, device)
    
    logger.info(f"ğŸ“ é¢„æµ‹ç»“æœ: {prediction}")
    
    return prediction

def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    logger.info("ğŸš€ æ•°å­¦éªŒè¯ç è¯†åˆ«æ¨¡å‹æµ‹è¯• v2")
    logger.info("=" * 60)
    
    # åŠ è½½æ¨¡å‹
    model, char_to_idx, idx_to_char, success = load_model_v2()
    if not success:
        return
    
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    model = model.to(device)
    logger.info(f"ğŸ”§ ä½¿ç”¨è®¾å¤‡: {device}")
    
    # æ˜¾ç¤ºé¢„æµ‹æ ·æœ¬
    show_prediction_samples(model, char_to_idx, idx_to_char, device)
    
    # æµ‹è¯•æ•°æ®é›†
    accuracy = test_dataset_v2(model, char_to_idx, idx_to_char, device, num_samples=20)
    
    # æ€§èƒ½åˆ†æ
    analyze_model_performance(model, char_to_idx, idx_to_char, device)
    
    # è¯„ä¼°ç»“æœ
    logger.info(f"\nğŸ’¡ è¯„ä¼°ç»“æœ:")
    if accuracy >= 80:
        logger.info("ğŸ‰ æ¨¡å‹è¡¨ç°ä¼˜ç§€ï¼è¯†åˆ«å‡†ç¡®ç‡å¾ˆé«˜")
    elif accuracy >= 60:
        logger.info("âœ… æ¨¡å‹è¡¨ç°è‰¯å¥½ï¼Œå¯ä»¥ç»§ç»­ä¼˜åŒ–")
    elif accuracy >= 30:
        logger.info("âš ï¸ æ¨¡å‹è¡¨ç°ä¸€èˆ¬ï¼Œå»ºè®®è°ƒæ•´è®­ç»ƒå‚æ•°")
    else:
        logger.info("ğŸ”´ æ¨¡å‹è¡¨ç°è¾ƒå·®ï¼Œå»ºè®®é‡æ–°è®­ç»ƒ")
        logger.info("ğŸ’¡ å¯èƒ½çš„é—®é¢˜ï¼š")
        logger.info("   - åºåˆ—é•¿åº¦ä¸åŒ¹é…")
        logger.info("   - å­¦ä¹ ç‡è®¾ç½®ä¸å½“")
        logger.info("   - è®­ç»ƒæ•°æ®ä¸è¶³")
        logger.info("   - æ¨¡å‹æ¶æ„éœ€è¦è°ƒæ•´")

if __name__ == "__main__":
    main() 